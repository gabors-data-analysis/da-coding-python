{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 19 – part II\n",
    "\n",
    "## Prediction with Lasso \n",
    "\n",
    "   - 3 sample approach:            \n",
    "       - train and test sample     \n",
    "         to do cross-validation    \n",
    "         or tuning                 \n",
    "       - hold-out sample to        \n",
    "         evaluate prediction       \n",
    "   - Model selection with:         \n",
    "     - lin.regression with cv      \n",
    "     - lasso (ridge & elastic net) \n",
    "   - Diagnostics and evaluation    \n",
    "     - which model gives           \n",
    "       best prediction on hold-out \n",
    "     - stability of the prediction \n",
    "     - further diagnostics with    \n",
    "         figures              \n",
    "                                            \n",
    "#### Case Study:                                 \n",
    "  - CH14B Predicting AirBnB apartment prices: selecting a regression model       \n",
    "\n",
    "####  Dataset:       \n",
    "    airbnb\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patchworklib as pw\n",
    "import patsy\n",
    "import statsmodels.formula.api as smf\n",
    "from mizani.formatters import percent_format\n",
    "from plotnine import *\n",
    "from skimpy import skim\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import work data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/airbnb_hackney_work.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define grouping variables which contains variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_lev = (\n",
    "    \"n_accommodates\",\n",
    "    \"n_beds\",\n",
    "    \"f_property_type\",\n",
    "    \"f_room_type\",\n",
    "    \"n_days_since\",\n",
    "    \"flag_days_since\",\n",
    ")\n",
    "basic_add = (\"f_bathroom\", \"f_cancellation_policy\", \"f_bed_type\")\n",
    "reviews = (\"f_number_of_reviews\", \"n_review_scores_rating\", \"flag_review_scores_rating\")\n",
    "poly_lev = (\"n_accommodates2\", \"n_days_since2\", \"n_days_since3\")\n",
    "# not use p_host_response_rate due to missing obs\n",
    "amenities = tuple(list(data.filter(regex=\"^d_.*\")))\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_diff_by_variables(df, factor_var, dummy_var, factor_lab, dummy_lab):\n",
    "    stats = df.groupby([factor_var, dummy_var]).agg(\n",
    "        Mean=(\"price\", np.mean), sd=(\"price\", np.std), size=(\"price\", \"size\")\n",
    "    )\n",
    "    stats[\"se\"] = stats[\"sd\"] / stats[\"size\"] ** (1 / 2)\n",
    "    stats[\"Mean_l\"] = stats[\"Mean\"] - (1.96 * stats[\"se\"])\n",
    "    stats[\"Mean_u\"] = stats[\"Mean\"] + (1.96 * stats[\"se\"])\n",
    "    stats = stats.drop([\"sd\", \"size\"], axis=1).reset_index()\n",
    "    plot = (\n",
    "        ggplot(\n",
    "            stats,\n",
    "            aes(\n",
    "                stats.columns[0],\n",
    "                stats.columns[2],\n",
    "                fill=\"factor(\" + stats.columns[1] + \")\",\n",
    "            ),\n",
    "        )\n",
    "        + geom_bar(stat=\"identity\", position=position_dodge(width=0.9))\n",
    "        + geom_errorbar(\n",
    "            aes(ymin=\"Mean_l\", ymax=\"Mean_u\"),\n",
    "            position=position_dodge(width=0.9),\n",
    "            width=0.25,\n",
    "        )\n",
    "        + scale_color_manual(name=dummy_lab, values=(\"blue\",\"red\"))\n",
    "        + scale_fill_manual(name=dummy_lab, values=(\"blue\",\"red\"))\n",
    "        + ylab(\"Mean Price\")\n",
    "        + xlab(factor_lab)\n",
    "        + theme_bw()\n",
    "        + theme(\n",
    "            panel_grid_major=element_blank(),\n",
    "            panel_grid_minor=element_blank(),\n",
    "            panel_border=element_blank(),\n",
    "            axis_line=element_line(),\n",
    "            legend_position=\"top\",\n",
    "            legend_box=\"vertical\",\n",
    "            legend_text=element_text(size=5),\n",
    "            legend_title=element_text(size=5, face=\"bold\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up room type interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = price_diff_by_variables(\n",
    "    data, \"f_room_type\", \"d_familykidfriendly\", \"Room type\", \"Family kid friendly\"\n",
    ")\n",
    "\n",
    "\n",
    "p2 = price_diff_by_variables(\n",
    "    data, \"f_room_type\", \"f_property_type\", \"Room type\", \"Property type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up cancelation policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = price_diff_by_variables(\n",
    "    data,\n",
    "    \"f_cancellation_policy\",\n",
    "    \"d_familykidfriendly\",\n",
    "    \"Cancellation policy\",\n",
    "    \"Family kid friendly\",\n",
    ")\n",
    "\n",
    "\n",
    "p4 = price_diff_by_variables(\n",
    "    data, \"f_cancellation_policy\", \"d_tv\", \"Cancellation policy\", \"TV\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look up room type interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p5 = price_diff_by_variables(data, \"f_property_type\", \"d_cats\", \"Property type\", \"Cats\")\n",
    "\n",
    "\n",
    "p6 = price_diff_by_variables(data, \"f_property_type\", \"d_dogs\", \"Property type\", \"Dogs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = pw.load_ggplot(p1, figsize=(3, 3))\n",
    "g2 = pw.load_ggplot(p2, figsize=(3, 3))\n",
    "g3 = pw.load_ggplot(p3, figsize=(3, 3))\n",
    "g4 = pw.load_ggplot(p4, figsize=(3, 3))\n",
    "g5 = pw.load_ggplot(p5, figsize=(3, 3))\n",
    "g6 = pw.load_ggplot(p6, figsize=(3, 3))\n",
    "\n",
    "interactions = (g1 | g2) / (g3 | g4 ) / (g5 | g6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the interaction terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummies suggested by graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = (\"f_room_type*f_property_type\", \"f_room_type*d_familykidfriendly\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Additional interactions of factors and dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = (\n",
    "    \"d_airconditioning*f_property_type\",\n",
    "    \"d_cats*f_property_type\",\n",
    "    \"d_dogs*f_property_type\",\n",
    ")\n",
    "X3 = (\n",
    "    \"(f_property_type + f_room_type + f_cancellation_policy + f_bed_type) * (\"\n",
    "    + \"+\".join(amenities)\n",
    "    + \")\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model setups\n",
    "\n",
    " Create models in levels models: 1-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eq1 = \"~ n_accommodates\"\n",
    "model_eq2 = \"~\" + \"+\".join(basic_lev)\n",
    "model_eq3 = \"~\" + \"+\".join(basic_lev + basic_add + reviews)\n",
    "model_eq4 = \"~\" + \"+\".join(basic_lev + basic_add + reviews + poly_lev)\n",
    "model_eq5 = \"~\" + \"+\".join(basic_lev + basic_add + reviews + poly_lev + X1)\n",
    "model_eq6 = \"~\" + \"+\".join(basic_lev + basic_add + reviews + poly_lev + X1 + X2)\n",
    "model_eq7 = \"~\" + \"+\".join(\n",
    "    basic_lev + basic_add + reviews + poly_lev + X1 + X2 + amenities\n",
    ")\n",
    "model_eq8 = (\n",
    "    \"~\"\n",
    "    + \"+\".join(basic_lev + basic_add + reviews + poly_lev + X1 + X2 + amenities)\n",
    "    + \"+\"\n",
    "    + X3\n",
    ")\n",
    "model_equations = [\n",
    "    model_eq1,\n",
    "    model_eq2,\n",
    "    model_eq3,\n",
    "    model_eq4,\n",
    "    model_eq5,\n",
    "    model_eq6,\n",
    "    model_eq7,\n",
    "    model_eq8,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a holdout set (20% of observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smp_size = data.shape[0] // 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random number generator: It will make results reproducable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20180123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create work and holdout set with sklearn's train_test_split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_work, data_holdout = train_test_split(data, test_size=smp_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize the Working data set:\n",
    "  1. estimate measures on the whole working sample (R2,BIC,RMSE)\n",
    "  2. DO K-fold cross validation to get proper Test RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "\n",
    "k = KFold(n_splits=n_folds, shuffle=False, random_state=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import KFold\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "\n",
    "def ols_crossvalidator(\n",
    "    formula: str, data: pd.DataFrame, n_folds=5, average_rmse=True\n",
    ") -> dict:\n",
    "    \"\"\"OLS cross-validator\n",
    "\n",
    "\n",
    "    Estimates `formula` equation with OLS and returns values of RMSE, R`2, No. coefficients,\n",
    "    BIC on `data`. Does k-fold cross-validation and either returns train and test RMSE for each\n",
    "    fold, or return averarage train and test RMSEs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    formula : str\n",
    "        Equation that is estimated by OLS.\n",
    "    data : pd.DataFrame\n",
    "        Database in a wide format.\n",
    "    n_folds : int, default=5\n",
    "        Number of folds. Must be at least 2.\n",
    "    average_rmse : bool, default=True\n",
    "        Whether to return the average train and test RMSE of the k-fold CV, or return\n",
    "        train and test RMSE-s for each fold.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Get dependent variable\n",
    "\n",
    "    y = formula.split(\"~\")[0].strip()\n",
    "\n",
    "    # Get statistics on the whole work data\n",
    "\n",
    "    model = smf.ols(formula, data=data).fit()\n",
    "\n",
    "    rsquared = model.rsquared\n",
    "    # n_coefficients = model.params.shape[0]\n",
    "    n_coefficients = (\n",
    "        model.df_model + 1\n",
    "    )  # This might differ from model.params.shape[0], because of collinear predictors\n",
    "    bic = model.bic\n",
    "    rmse_alldata = rmse(model.predict(), data[y])\n",
    "\n",
    "    # Calculating test and train RMSE-s for each fold\n",
    "\n",
    "    k = KFold(n_splits=n_folds, shuffle=False, random_state=None)\n",
    "\n",
    "    rmse_train = []\n",
    "    rmse_test = []\n",
    "\n",
    "    for train_index, test_index in k.split(data):\n",
    "\n",
    "        data_train, data_test = data.iloc[train_index, :], data.iloc[test_index, :]\n",
    "\n",
    "        model = smf.ols(formula, data=data_train).fit()\n",
    "\n",
    "        rmse_train.append(rmse(data_train[y], model.predict(data_train)))\n",
    "        rmse_test.append(rmse(data_test[y], model.predict(data_test)))\n",
    "\n",
    "    if average_rmse:\n",
    "        rmse_train = np.mean(rmse_train)\n",
    "        rmse_test = np.mean(rmse_test)\n",
    "\n",
    "    return {\n",
    "        \"RMSE\": rmse_alldata,\n",
    "        \"R-squared\": rsquared,\n",
    "        \"BIC\": bic,\n",
    "        \"Coefficients\": n_coefficients,\n",
    "        \"Training RMSE\": rmse_train,\n",
    "        \"Test RMSE\": rmse_test,\n",
    "    }\n",
    "\n",
    "\n",
    "def summarize_cv(cvlist, stat=\"rmse\"):\n",
    "    \"\"\"\n",
    "    Summarises cross-validated OLS regression results received from `cv_reg`.\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame(\n",
    "        {\"Model \" + str(x + 1): cvlist[x][stat] for x in range(len(cv_list))}\n",
    "    )\n",
    "    result[\"Resample\"] = [\"Fold\" + str(x + 1) for x in range(len(cvlist[0][stat]))]\n",
    "    result = result.set_index(\"Resample\")\n",
    "    result = pd.concat([result, pd.DataFrame(result.mean(), columns=[\"Average\"]).T])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_list = []\n",
    "for model_eq in model_equations:\n",
    "    cv_list += [\n",
    "        ols_crossvalidator(\"price\" + model_eq, data_work, n_folds, average_rmse=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_folds = (\n",
    "    pd.DataFrame(\n",
    "        [cv[\"Test RMSE\"] for cv in cv_list],\n",
    "        index=[\"Model \" + str(i + 1) for i in range(len(cv_list))],\n",
    "        columns=[\"Fold\" + str(i + 1) for i in range(len(cv_list[0][\"Test RMSE\"]))],\n",
    "    )\n",
    "    .assign(Average=lambda x: x.mean(axis=1))\n",
    "    .T.round(2)\n",
    ")\n",
    "rmse_test_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-estimate the same models with `average_rmse=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_list = []\n",
    "for model_eq in model_equations:\n",
    "    cv_list += [\n",
    "        ols_crossvalidator(\"price\" + model_eq, data_work, n_folds, average_rmse=True)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_model_fits = (\n",
    "    pd.DataFrame(cv_list)\n",
    "    .round(2)\n",
    "    .assign(\n",
    "        Model=[\"M\" + str(i + 1) for i in range(len(cv_list))],\n",
    "        BIC=lambda x: x[\"BIC\"].astype(int),\n",
    "        Coefficients=lambda x: x[\"Coefficients\"].astype(int),\n",
    "    )\n",
    "    .filter([\"Model\", \"Coefficients\", \"R-squared\", \"BIC\", \"Training RMSE\", \"Test RMSE\"])\n",
    ")\n",
    "compare_model_fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE training vs test graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(\n",
    "        compare_model_fits.melt(\n",
    "            id_vars=\"Coefficients\", value_vars=[\"Training RMSE\", \"Test RMSE\"]\n",
    "        ),\n",
    "        aes(x=\"factor(Coefficients)\", y=\"value\", color=\"variable\", group=\"variable\"),\n",
    "    )\n",
    "    + geom_line(size=1, show_legend=True, na_rm=True)\n",
    "    + scale_color_manual(name=\" \", values=(\"red\", \"blue\"))\n",
    "    + scale_y_continuous(name=\"RMSE\", limits=(30, 43), breaks=np.arange(30, 44, 2))\n",
    "    + scale_x_discrete(name=\"Number of coefficients\", expand=(0.01, 0.01))\n",
    "    + theme_bw()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso - first, we do cross validation by hand for educational purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take model equation 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_model_8 = model_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define range for lambdas – the algo will look only in this set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.arange(0.05, 1.01, 0.05)\n",
    "print(lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and test sets to perform the cross validation on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_work, X_work = patsy.dmatrices(\"price\" + vars_model_8, data_work)\n",
    "X_work_featnames = X_work.design_info.column_names\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_work, y_work, test_size=smp_size, random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cross-validate lambda-s (which is Lasso's hyperparameter) one has to scale the feature matrix.\n",
    "\n",
    "Note: do this separately on train and test X-sets to avoid information spillover between sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "X_work = scaler.fit_transform(X_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validate, now manualy in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r_squared = np.zeros(len(lambdas))\n",
    "test_r_squared = np.zeros(len(lambdas))\n",
    "train_rmse = np.zeros(len(lambdas))\n",
    "test_rmse = np.zeros(len(lambdas))\n",
    "\n",
    "for ind, i in enumerate(lambdas):\n",
    "    reg = Lasso(alpha=i)\n",
    "    reg.fit(X_train, y_train)\n",
    "    train_r_squared[ind] = reg.score(X_train, y_train)\n",
    "    test_r_squared[ind] = reg.score(X_test, y_test)\n",
    "    train_rmse[ind] = rmse(reg.predict(X_train), y_train.reshape(1,-1)[0])\n",
    "    test_rmse[ind] = rmse(reg.predict(X_test), y_test.reshape(1,-1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the evolution of $R^2$ depending on lambdas in the train and test set. Recall bias-variance trade-off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_data = pd.DataFrame(\n",
    "    {\n",
    "        \"$R^2$ Test set\": test_r_squared,\n",
    "        \"$R^2$ Training set\": train_r_squared,\n",
    "        \"lambda\": lambdas,\n",
    "    }\n",
    ").melt(id_vars=[\"lambda\"])\n",
    "\n",
    "r_squared_data[\"variable\"] = (\n",
    "    r_squared_data[\"variable\"]\n",
    "    .astype(\"category\")\n",
    "    .cat.reorder_categories([\"$R^2$ Training set\", \"$R^2$ Test set\"])\n",
    ")\n",
    "\n",
    "\n",
    "(\n",
    "    ggplot(r_squared_data, aes(x=\"lambda\", y=\"value\", color=\"variable\"))\n",
    "    + geom_point()\n",
    "    + geom_line(size=1, show_legend=False, na_rm=True)\n",
    "    + scale_color_manual(name=\"\", values=(\"blue\", \"red\"))\n",
    "    + scale_y_continuous(name=\"$R^2$\")\n",
    "        + scale_x_continuous(name=\"$\\lambda$\", limits=(0,1))\n",
    "    + theme_bw()\n",
    "    + theme(subplots_adjust={\"wspace\": 0.25}, legend_title=element_blank())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the evolution of RMSE depending on lambdas in the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_data = pd.DataFrame(\n",
    "    {\n",
    "        \"RMSE Test set\": test_rmse,\n",
    "        \"RMSE Training set\": train_rmse,\n",
    "        \"lambda\": lambdas,\n",
    "    }\n",
    ").melt(id_vars=[\"lambda\"])\n",
    "\n",
    "r_squared_data[\"variable\"] = (\n",
    "    r_squared_data[\"variable\"]\n",
    "    .astype(\"category\")\n",
    "    .cat.reorder_categories([\"RMSE Training set\", \"RMSE Test set\"])\n",
    ")\n",
    "\n",
    "\n",
    "(\n",
    "    ggplot(r_squared_data, aes(x=\"lambda\", y=\"value\", color=\"variable\"))\n",
    "    + geom_point()\n",
    "    + geom_line(size=1, show_legend=False, na_rm=True)\n",
    "    + scale_color_manual(name=\"\", values=(\"blue\", \"red\"))\n",
    "    + scale_y_continuous(name=\"RMSE\", limits=(31, 38))\n",
    "    + scale_x_continuous(name=\"$\\lambda$\", limits=(0, 1))\n",
    "    + theme_bw()\n",
    "    + theme(subplots_adjust={\"wspace\": 0.25}, legend_title=element_blank())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the lambda with lowesr test $RMSE$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lam = pd.DataFrame(test_rmse, columns=[\"RMSE test\"])\n",
    "df_lam[\"lambda\"] = lambdas\n",
    "\n",
    "df_lam.loc[df_lam[\"RMSE test\"].idxmin()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-estimate Lasso model with cross-validated lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_best = Lasso(alpha=df_lam.loc[lambda x: x[\"RMSE test\"].idxmin()][\"lambda\"])\n",
    "lasso_best.fit(X_work, y_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See coefficients that are greater than 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notnull_lasso_coefs = pd.DataFrame(\n",
    "    lasso_best.coef_, index=X_work_featnames, columns=[\"coefficient\"]\n",
    ").loc[lambda x: x[\"coefficient\"] != 0]\n",
    "notnull_lasso_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MSE on test on the test set, within the work set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, lasso_best.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One can alternatively do cross validation with sklearn's LassoCV\n",
    "\n",
    "In production, this is much easier, we did all above step by step manually for educational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso_cv_fit = LassoCV(alphas=lambdas, cv=5, random_state=42).fit(X_work, y_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the algo choose a different alpha. This is because it did 5 fold CV for each alpha and choose the one with the best average test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_fit.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_lambda_folds = (\n",
    "    pd.DataFrame(lasso_cv_fit.mse_path_, index=lambdas[::-1])\n",
    "    .apply(np.sqrt)\n",
    "    .mean(axis=1)\n",
    "    .to_frame(name=\"test RMSE\")\n",
    "    .rename_axis(\"$\\lambda$\")\n",
    ")\n",
    "rmse_lambda_folds.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notnull_lasso_coefs = (\n",
    "    pd.DataFrame(lasso_cv_fit.coef_, index=X_work_featnames, columns=[\"coefficient\"])\n",
    "    .loc[lambda x: x[\"coefficient\"] != 0]\n",
    "    .round(3)\n",
    ")\n",
    "notnull_lasso_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_model_fits.loc[8, :] = {\n",
    "    \"Model\": \"Lasso\",\n",
    "    \"Coefficients\": notnull_lasso_coefs.shape[0],\n",
    "    \"Test RMSE\": rmse_lambda_folds.loc[lasso_cv_fit.alpha_].round(2).values[0],\n",
    "}\n",
    "\n",
    "compare_model_fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net\n",
    "\n",
    "We can also cross-validate Elastic Net regression which is a regularized regression method that linearly combines the L1 and L2 penalties of the LASSO and Ridge methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNetCV's main parameter is `l1_ratio` (default=0.5, a float between 0 and 1 passed to ElasticNet (scaling between l1 and l2 penalties). For `l1_ratio` = 0 the penalty is an L2 penalty. For `l1_ratio` = 1 it is an L1 penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validate through a set of `l1_ratio`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnet_cv_fit = ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], cv=5, random_state=0).fit(\n",
    "    X_work, y_work\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `l1_ratios` is 1, this means that the cross validated best model used only L1 penalty which is used by the LASSO model (as a lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnet_cv_fit.l1_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnet_cv_fit.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Evaluate performance on the hold-out sample\n",
    "\n",
    "\n",
    "Let us check only Models: 3, 7 and LASSO and ElasticNet\n",
    "\n",
    "\n",
    "First re-fit OLS models on the whole work data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = smf.ols(\"price\" + model_eq3, data=data_work).fit(cov_type=\"HC0\")\n",
    "model7 = smf.ols(\"price\" + model_eq7, data=data_work).fit(cov_type=\"HC0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get standardized X matrix on holdout for Lasso, for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_holdout = patsy.dmatrices(\"price\" + vars_model_8, data_holdout)\n",
    "X_holdout = scaler.fit_transform(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_performances = pd.DataFrame(\n",
    "    {\n",
    "        \"Model 3\": rmse(model3.predict(data_holdout), data_holdout[\"price\"]),\n",
    "        \"Model 7\": rmse(model7.predict(data_holdout), data_holdout[\"price\"]),\n",
    "        \"LASSO\": rmse(lasso_cv_fit.predict(X_holdout), data_holdout[\"price\"]),\n",
    "        \"ElasticNet\": rmse(elasticnet_cv_fit.predict(X_holdout), data_holdout[\"price\"]),\n",
    "    },\n",
    "    index=[\"RMSE on holdout\"],\n",
    ").T.round(2)\n",
    "holdout_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the predicted values of model 7 in data_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holdout[\"predicted_price\"] = model7.predict(data_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot predicted price vs. actual price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(data=data_holdout)\n",
    "    + geom_point(\n",
    "        aes(y=\"price\", x=\"predicted_price\"),\n",
    "        color=\"blue\",\n",
    "        size=1,\n",
    "        alpha=0.7,\n",
    "        show_legend=False,\n",
    "        na_rm=True,\n",
    "    )\n",
    "    + geom_segment(\n",
    "        aes(x=0, y=0, xend=350, yend=350), size=0.5, linetype=\"dashed\", color=\"red\"\n",
    "    )\n",
    "    + coord_equal()  # to get equally lengthed y and x axis\n",
    "    + scale_x_continuous(\n",
    "        expand=(0.01, 0.01), limits=(0, 350), breaks=np.arange(0, 351, 50)\n",
    "    )\n",
    "    + scale_y_continuous(\n",
    "        expand=(0.01, 0.01), limits=(0, 350), breaks=np.arange(0, 351, 50)\n",
    "    )\n",
    "    + labs(y=\"Price (US dollars)\", x=\"Predicted price  (US dollars)\")\n",
    "    + theme_bw()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo predicted values at 80% PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_agg_by_nacc = (\n",
    "    model7.get_prediction(data_holdout)\n",
    "    .summary_frame(alpha=0.2)\n",
    "    .filter([\"mean\", \"obs_ci_lower\", \"obs_ci_upper\"])\n",
    "    .rename(columns={\"mean\": \"predicted_price\"})\n",
    "    .assign(n_accommodates=data_holdout[\"n_accommodates\"].values)\n",
    "    .groupby(by=[\"n_accommodates\"])\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction interval by apartment size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(prediction_agg_by_nacc, aes(x=\"n_accommodates\"))\n",
    "    + geom_bar(aes(y=\"predicted_price\"), stat=\"identity\", fill=\"blue\", alpha=0.7)\n",
    "    + geom_errorbar(\n",
    "        aes(ymin=\"obs_ci_lower\", ymax=\"obs_ci_upper\"), color=\"red\", width=0.2\n",
    "    )\n",
    "    + scale_y_continuous(name=\"Predicted price (US dollars)\")\n",
    "    + scale_x_continuous(name=\"Accomodates (Persons)\", breaks=np.arange(1, 8, 1))\n",
    "    + scale_color_manual(values=(\"red\", \"red\"))\n",
    "    + theme_bw()\n",
    "    + theme(legend_title=element_blank(), legend_position=\"none\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two extras, if we have time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. We may check how the coefficients are changing as lambda changes for LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import lasso_path\n",
    "\n",
    "eps = 5e-3  # the smaller it is the longer is the path\n",
    "lambdas_lasso, coefs_lasso, _ = lasso_path(X_work, y_work, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "colors = cycle([\"b\", \"r\", \"g\", \"c\", \"k\"])\n",
    "neg_log_lambdas_lasso = -np.log10(lambdas_lasso)\n",
    "for coef_l, c in zip(coefs_lasso[0], colors):\n",
    "    l1 = plt.plot(neg_log_lambdas_lasso, coef_l, c=c)\n",
    "\n",
    "plt.xlabel(\"-Log(lambda)\")\n",
    "plt.ylabel(\"coefficients\")\n",
    "plt.title(\"LASSO Paths\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  Using One-Standard-Error (1SE) rule for selecting a more parsimonious model:\n",
    "\n",
    "Get the 1SE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_se = rmse_lambda_folds[\"test RMSE\"].std() / np.sqrt(rmse_lambda_folds.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a decision rule: minimum RMSE + 1SE\n",
    "\n",
    "One can see that we may even have lambda = 0.5 as well based on 1SE rule... (but note, that lambda in (0,Inf[ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_lambda_folds[\"RMSE + 1SE\"] = rmse_lambda_folds[\"test RMSE\"].min() + one_se\n",
    "\n",
    "rmse_lambda_folds.loc[lambda x: x[\"test RMSE\"] < x[\"RMSE + 1SE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_max = (\n",
    "    rmse_lambda_folds.loc[lambda x: x[\"test RMSE\"] < x[\"RMSE + 1SE\"]]\n",
    "    .reset_index()[\"$\\lambda$\"]\n",
    "    .max()\n",
    ")\n",
    "\n",
    "lambda_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare:\n",
    "\n",
    "Run parsimonious LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_parsimonious_fit = LassoCV(alphas=[lambda_max], cv=5, random_state=42).fit(X_work, y_work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can get the coefficients as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notnull_lasso_coefs = (\n",
    "    pd.DataFrame(lasso_cv_fit.coef_, index=X_work_featnames, columns=[\"coefficient\"])\n",
    "    .loc[lambda x: x[\"coefficient\"] != 0]\n",
    "    .round(3)\n",
    ")\n",
    "notnull_lasso_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, test holdout performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_performances.loc[\"Parsim. LASSO\"] = rmse(\n",
    "    lasso_parsimonious_fit.predict(X_holdout), data_holdout[\"price\"]\n",
    ")\n",
    "\n",
    "holdout_performances.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we got a worse holdout prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c01754e8627d0ea60fdf9a984fbf743943cf4db47884120dd04bfc512143b077"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
